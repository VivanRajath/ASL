ASL Hand Sign Recognition using MediaPipe & Random Forest
This project performs American Sign Language (ASL) letter recognition using MediaPipe for hand tracking and a Random Forest model trained on landmark data.

ğŸ“ Project Structure
ASL-Detector/
â”œâ”€â”€ dataset/ â†’ asl_alphabet_train/ (A/, B/, ..., Z/)
â”œâ”€â”€ train.py â†’ Train the model
â”œâ”€â”€ test.py â†’ Evaluate the model
â”œâ”€â”€ predict.py â†’ Real-time webcam ASL detection
â”œâ”€â”€ model.py â†’ Loads MediaPipe hand model
â”œâ”€â”€ utils.py â†’ Extracts hand landmarks
â”œâ”€â”€ requirements.txt â†’ Python dependencies
â”œâ”€â”€ asl_model.pkl â†’ Trained model (auto-generated)
â””â”€â”€ README.md â†’ Project documentation

ğŸ“¦ Installation
Clone this repository:
git clone https://github.com/yourusername/ASL-Detector.git
cd ASL-Detector

(Optional) Create a virtual environment:
python -m venv venv
source venv/bin/activate
(On Windows: venv\Scripts\activate)

Install dependencies:
pip install -r requirements.txt

ğŸ“‚ Dataset Setup
Download the ASL Alphabet dataset from Kaggle:
https://www.kaggle.com/datasets/grassknoted/asl-alphabet

Extract it like this:
dataset/asl_alphabet_train/A/
dataset/asl_alphabet_train/B/
...

ğŸ‹ï¸â€â™‚ï¸ Train the Model
Run:
python train.py

This creates asl_model.pkl.

ğŸ§ª Test the Model
Run:
python test.py

ğŸ¥ Real-Time ASL Detection
Run:
python predict.py

âœ‹ Show your hand signs in front of your webcam.
Press q to quit.

âœ… Requirements
mediapipe

opencv-python

scikit-learn

joblib

tqdm

Install using:
pip install -r requirements.txt

ğŸš€ Future Improvements
GUI for interaction

Deep Learning upgrade

Webcam-based custom training


ASL Hand Sign Recognition using MediaPipe & Random Forest
This project uses MediaPipe to extract hand landmarks and a Random Forest classifier to recognize American Sign Language (ASL) letters in real-time via webcam or from static image datasets.

Project Structure

ASL/
â”‚
â”œâ”€â”€ dataset/
â”‚   â””â”€â”€ asl_alphabet_train/   # Kaggle dataset folder (A/, B/, ..., Z/)
â”‚
â”œâ”€â”€ train.py                  # Train model from dataset
â”œâ”€â”€ test.py                   # Evaluate model accuracy
â”œâ”€â”€ predict.py                # Real-time ASL detection from webcam
â”‚
â”œâ”€â”€ model.py                  # MediaPipe hand model loader
â”œâ”€â”€ utils.py                  # Landmark extraction and preprocessing
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # Project documentation (this file)
â””â”€â”€ asl_model.pkl             # Trained model (generated after training)



ğŸ§ª Dataset
Use the Kaggle dataset: https://www.kaggle.com/datasets/grassknoted/asl-alphabet

âš™ï¸ Installation
git clone https://github.com/yourusername/ASL.git
cd ASL

# Create virtual environment (optional)
python -m venv venv
source venv/bin/activate   # or venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
ğŸ‹ï¸â€â™‚ï¸ Training
Train the model using MediaPipe hand landmarks:


python train.py
This will generate a trained model saved as asl_model.pkl.

Evaluate the trained model:


python test.py
Youâ€™ll get the test accuracy printed in the console.

Real-Time Prediction (Webcam)
Use your webcam to detect ASL signs in real time:

python predict.py
âœ‹ Make sure your hand is clearly visible in the camera frame. Press q to exit.

Utilities
model.py: Initializes MediaPipe hand detection model

utils.py: Extracts 21 hand landmark coordinates (x, y, z)

Requirements
opencv-python
mediapipe
scikit-learn
joblib
tqdm
ğŸš€ Future Enhancements
Add GUI with sign history

Use CNN with landmark heatmaps for better accuracy

Train using your own webcam gesture data


ğŸ“„ License
MIT License

